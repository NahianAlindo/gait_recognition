{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model with blocks Bi-GRU.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2VLKMypislJ_",
        "46JTDsKIwaov",
        "qjGQsawPxWEb",
        "oVk3TBGOyCnT",
        "nTR0FW2qzglG",
        "aKFZ_7IMzglH",
        "VztWrRCA2pRd",
        "YRezZ-Um0fYf",
        "ExiUFOeA0pua",
        "IqmCcxhXqzr_",
        "fwWBPV9HJUhg",
        "bqMIrG_L0dG1",
        "TL-gQ6yY0dG2",
        "G3UeC-2t0dG3"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9HBiYwFk1qn"
      },
      "source": [
        "# Mount Drive and Accelerator status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVYiI5UCcsu8",
        "outputId": "9b32d7a5-ca2f-4617-c6ec-440f74ca7626"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec  7 13:27:19 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P8    33W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn8udKehjhLj",
        "outputId": "5d92c75d-d897-4248-8eea-94410cfced86"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcYmsM_ueY4f",
        "outputId": "e49d8276-7733-4996-bb2a-0eed5673e03a"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "try:\n",
        "    tpu = False\n",
        "    assert torch.cuda.is_available()\n",
        "    gpu = True\n",
        "    ! nvidia-smi\n",
        "except:\n",
        "    tpu = True\n",
        "    gpu = False\n",
        "    if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "        print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "    else:\n",
        "        tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "        print ('TPU address is', tpu_address)\n",
        "    import tensorflow as tf\n",
        "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)\n",
        "    tf.config.experimental_connect_to_cluster(resolver)\n",
        "    # This is the TPU initialization code that has to be at the beginning.\n",
        "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "    print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "    strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec  7 13:28:13 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   68C    P8    33W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsN8_Rrlkyeo",
        "outputId": "3d9ed314-88c2-45aa-d22b-a0b7d8d09aa3"
      },
      "source": [
        "! pip install keras_tuner"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.1.0-py3-none-any.whl (98 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 20 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 40 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 71 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 81 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 92 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 98 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (1.19.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (2.7.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (5.5.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (21.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (2.23.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (57.4.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (2.6.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras_tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras_tuner) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras_tuner) (3.0.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras_tuner) (0.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras_tuner) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras_tuner) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras_tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras_tuner) (2021.10.8)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (0.12.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (0.37.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (1.42.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (3.17.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras_tuner) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras_tuner) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras_tuner) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras_tuner) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras_tuner) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras_tuner) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras_tuner) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras_tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras_tuner) (3.1.1)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.1.0 kt-legacy-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd1Jw0EUk78i"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nte45gPrlVT2"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "import keras_tuner as kt\n",
        "import os\n",
        "import numpy as np\n",
        "# import keras\n",
        "import keras.backend as K\n",
        "from tensorflow.keras.layers import Input, Masking, LSTM, Dropout, Permute, Conv1D, BatchNormalization, Activation, GlobalAveragePooling1D, concatenate, multiply, Reshape, Dense, GRU, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import Input\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.constraints import max_norm as maxnorm\n",
        "import seaborn as sns\n",
        "import tensorflow.keras.metrics as metrics\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCIF7zdalmPO"
      },
      "source": [
        "# Utility Functions for loading dataset, plots and performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfsCK46Tlu0s"
      },
      "source": [
        "def load_X(path):\n",
        "    X_signals = []\n",
        "    files = os.listdir(path)\n",
        "    files.sort(key=str.lower)\n",
        "    #['train_acc_x.txt', 'train_acc_y.txt', 'train_acc_z.txt', 'train_gyr_x.txt', 'train_gyr_y.txt', 'train_gyr_z.txt']\n",
        "    for my_file in files:\n",
        "        fileName = os.path.join(path,my_file)\n",
        "        file = open(fileName, 'r')\n",
        "        X_signals.append(\n",
        "            [np.array(cell, dtype=np.float32) for cell in [\n",
        "                row.strip().split(' ') for row in file\n",
        "            ]]\n",
        "        )\n",
        "        file.close()\n",
        "        #X_signals = 6*totalStepNum*128\n",
        "    X_signals = np.transpose(np.array(X_signals), (1, 0, 2))#(totalStepNum*6*128)\n",
        "    return X_signals.reshape(-1,6,128,1)#(totalStepNum*6*128*1)\n",
        "\n",
        "def load_y(y_path):\n",
        "    file = open(y_path, 'r')\n",
        "    # Read dataset from disk, dealing with text file's syntax\n",
        "    y_ = np.array(\n",
        "        [elem for elem in [\n",
        "            row.replace('  ', ' ').strip().split(' ') for row in file\n",
        "        ]],\n",
        "        dtype=np.int32\n",
        "    )\n",
        "    file.close()\n",
        "    # Substract 1 to each output class for friendly 0-based indexing\n",
        "    y_ = y_ - 1\n",
        "    #one_hot\n",
        "    y_ = y_.reshape(len(y_))\n",
        "    n_values = int(np.max(y_)) + 1\n",
        "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]  # Returns FLOATS"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J5kEW01l5FY"
      },
      "source": [
        "def get_test_performance(model, X_test, test_label):\n",
        "    score=model.evaluate(X_test,test_label,verbose=1)\n",
        "    print(f'Test loss:{score[0]}')\n",
        "    print(f'Test accuracy:{score[1]}')\n",
        "    print(f'Test Recall: {score[3]}')\n",
        "    print(f'Test AUC: {score[2]}')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gSCx8cml75h"
      },
      "source": [
        "def plot_performance(X_train, train_label, history):\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    try:\n",
        "        plt.plot(history.history['val_accuracy'])\n",
        "        plt.title('model accuracy')\n",
        "        plt.ylabel('accuracy')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'val'], loc='upper left')\n",
        "    except:\n",
        "        pass\n",
        "    try:\n",
        "        plt.legend(['val'], loc='upper left')\n",
        "    except:\n",
        "        pass\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(history.history['loss'])\n",
        "    try:\n",
        "        plt.plot(history.history['val_loss'])\n",
        "    except:\n",
        "        pass\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train'], loc='upper left')\n",
        "    try:\n",
        "        plt.legend(['val'], loc='upper left')\n",
        "    except:\n",
        "        pass\n",
        "    plt.show()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdsZEDohmFvr"
      },
      "source": [
        "def squeeze_excite_block(tensor, ratio=16):\n",
        "    init = tensor\n",
        "    # channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    filters = init.shape[-1]\n",
        "    se_shape = (1, filters)\n",
        "\n",
        "    se = GlobalAveragePooling1D()(init)\n",
        "    se = Reshape(se_shape)(se)\n",
        "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "\n",
        "    # if K.image_data_format() == 'channels_first':\n",
        "    #     se = Permute((3, 1, 2))(se)\n",
        "\n",
        "    x = multiply([init, se])\n",
        "    return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlffWBOlmxrl"
      },
      "source": [
        "# Tuner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcqHbcVir0W6"
      },
      "source": [
        "np.random.seed(42)\n",
        "num_classes = 118\n",
        "X_train = load_X('/content/drive/Shareddrives/MMH/TIFS20/Dataset #1/train/Inertial Signals')\n",
        "X_test = load_X('/content/drive/Shareddrives/MMH/TIFS20/Dataset #1/test/Inertial Signals')\n",
        "train_label = load_y('/content/drive/Shareddrives/MMH/TIFS20/Dataset #1/train/y_train.txt')\n",
        "test_label = load_y('/content/drive/Shareddrives/MMH/TIFS20/Dataset #1/test/y_test.txt')\n",
        "shape = ((X_train.shape[1], X_train.shape[2]), train_label.shape[1])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g58tB7pmzl_"
      },
      "source": [
        "def post_se(hp):\n",
        "    ip = Input(shape=(6, 128))\n",
        "    x = Masking()(ip)\n",
        "    x = Bidirectional(GRU(units=hp.Choice('Bi-GRU_1', values = [8,16,32,64,128,256,512])))(x)\n",
        "    # x = Bidirectional(LSTM(units=hp.Choice('Bi-GRU_2', values = [8,16,32,64,128,256,512])))(x)\n",
        "    x = Dropout(hp.Choice(name='Dropout', values = [0.0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]))(x)\n",
        "    y = Permute((2, 1))(ip)\n",
        "    y = Conv1D(hp.Choice('conv_1_filter', values = [32,64,128,256,512]), hp.Choice(name='conv_1_filter_size', values = [3,5,7,8,9]), padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = squeeze_excite_block(y)\n",
        "    y = Conv1D(hp.Choice('conv_2_filter', values = [32,64,128,256,512]), hp.Choice(name='conv_2_filter_size',values = [3,5,7,8,9]), padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = squeeze_excite_block(y)\n",
        "    y = Conv1D(hp.Choice('conv_3_filter', values = [32,64,128,256,512,]), hp.Choice(name='conv_3_filter_size',values = [3,5,7,8,9]), padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = GlobalAveragePooling1D()(y)\n",
        "    x = concatenate([x,y])\n",
        "    # batch_size = hp.Choice('batch_size', values=[32, 64, 128, 256, 512, 1024, 2048, 4096])\n",
        "    out = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(ip, out)\n",
        "    if gpu:\n",
        "        opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    if tpu:\n",
        "        opt = keras.optimizers.Adam(learning_rate=8*0.001)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "    # model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7P_X7a8Hq5an"
      },
      "source": [
        "# Tune on 90% data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je5TbDAWnf3r",
        "outputId": "53550cd9-05e5-4206-f0f2-5463de8447c9"
      },
      "source": [
        "if gpu:\n",
        "    tuner = kt.tuners.BayesianOptimization(post_se,\n",
        "        objective='val_accuracy',\n",
        "        max_trials=30,\n",
        "        seed=42,\n",
        "        project_name='Model_gpu')\n",
        "    # Will stop training if the \"val_loss\" hasn't improved in 30 epochs.\n",
        "    tuner.search(X_train, train_label, epochs=200, validation_split=0.1, shuffle=True, callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)])\n",
        "\n",
        "if tpu:\n",
        "    print(\"TPU\")\n",
        "    with strategy.scope():\n",
        "        tuner = kt.tuners.BayesianOptimization(post_se,\n",
        "            objective='val_accuracy',\n",
        "            max_trials=30,\n",
        "            seed=42,\n",
        "            project_name='Model_tpu')\n",
        "        # Will stop training if the \"val_loss\" hasn't improved in 30 epochs.\n",
        "        tuner.search(X_train, train_label, epochs=200, validation_split=0.1, shuffle=True, callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 6 Complete [01h 26m 47s]\n",
            "val_accuracy: 0.9966777563095093\n",
            "\n",
            "Best val_accuracy So Far: 0.9966777563095093\n",
            "Total elapsed time: 06h 11m 20s\n",
            "\n",
            "Search: Running Trial #7\n",
            "\n",
            "Hyperparameter    |Value             |Best Value So Far \n",
            "Bi-GRU_1          |8                 |8                 \n",
            "Dropout           |0.8               |0.8               \n",
            "conv_1_filter     |512               |32                \n",
            "conv_1_filter_size|9                 |9                 \n",
            "conv_2_filter     |32                |256               \n",
            "conv_2_filter_size|3                 |3                 \n",
            "conv_3_filter     |32                |512               \n",
            "conv_3_filter_size|9                 |3                 \n",
            "\n",
            "Epoch 1/200\n",
            "932/932 [==============================] - 44s 35ms/step - loss: 2.3356 - accuracy: 0.4606 - val_loss: 0.8804 - val_accuracy: 0.7982\n",
            "Epoch 2/200\n",
            "932/932 [==============================] - 31s 33ms/step - loss: 0.6087 - accuracy: 0.8679 - val_loss: 0.3243 - val_accuracy: 0.9396\n",
            "Epoch 3/200\n",
            "932/932 [==============================] - 31s 33ms/step - loss: 0.3020 - accuracy: 0.9321 - val_loss: 0.2712 - val_accuracy: 0.9351\n",
            "Epoch 4/200\n",
            "932/932 [==============================] - 31s 33ms/step - loss: 0.2071 - accuracy: 0.9506 - val_loss: 0.1701 - val_accuracy: 0.9592\n",
            "Epoch 5/200\n",
            "932/932 [==============================] - 31s 33ms/step - loss: 0.1605 - accuracy: 0.9608 - val_loss: 0.1335 - val_accuracy: 0.9683\n",
            "Epoch 6/200\n",
            "932/932 [==============================] - 31s 34ms/step - loss: 0.1331 - accuracy: 0.9680 - val_loss: 0.1203 - val_accuracy: 0.9701\n",
            "Epoch 7/200\n",
            "932/932 [==============================] - 30s 33ms/step - loss: 0.1101 - accuracy: 0.9729 - val_loss: 0.1077 - val_accuracy: 0.9695\n",
            "Epoch 8/200\n",
            "932/932 [==============================] - 30s 32ms/step - loss: 0.1010 - accuracy: 0.9749 - val_loss: 0.1028 - val_accuracy: 0.9707\n",
            "Epoch 9/200\n",
            "932/932 [==============================] - 31s 33ms/step - loss: 0.0889 - accuracy: 0.9766 - val_loss: 0.1767 - val_accuracy: 0.9432\n",
            "Epoch 10/200\n",
            "932/932 [==============================] - 31s 33ms/step - loss: 0.0748 - accuracy: 0.9801 - val_loss: 0.1062 - val_accuracy: 0.9680\n",
            "Epoch 11/200\n",
            "932/932 [==============================] - 31s 33ms/step - loss: 0.0663 - accuracy: 0.9828 - val_loss: 0.1183 - val_accuracy: 0.9698\n",
            "Epoch 12/200\n",
            "932/932 [==============================] - 31s 33ms/step - loss: 0.0663 - accuracy: 0.9817 - val_loss: 0.1334 - val_accuracy: 0.9616\n",
            "Epoch 13/200\n",
            "932/932 [==============================] - 31s 34ms/step - loss: 0.0610 - accuracy: 0.9838 - val_loss: 0.0658 - val_accuracy: 0.9825\n",
            "Epoch 14/200\n",
            "932/932 [==============================] - 31s 34ms/step - loss: 0.0546 - accuracy: 0.9848 - val_loss: 0.0712 - val_accuracy: 0.9804\n",
            "Epoch 15/200\n",
            "207/932 [=====>........................] - ETA: 23s - loss: 0.0401 - accuracy: 0.9905"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSruVlwlIv0T"
      },
      "source": [
        "# MODEL DEFINITION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f70nWuFnIufC"
      },
      "source": [
        "def MLSTM_FCN(shape, num_classes):\n",
        "    x = Input(shape=(6, 128))\n",
        "    ip = x\n",
        "    x = Masking()(ip)\n",
        "    x = GRU(units=8)(x)\n",
        "    x = Dropout(0.8)(x)\n",
        "    y = Permute((2, 1))(ip)\n",
        "    y = Conv1D(32, 9, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = squeeze_excite_block(y)\n",
        "    y = Conv1D(256, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = squeeze_excite_block(y)\n",
        "    y = Conv1D(512, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = GlobalAveragePooling1D()(y)\n",
        "    x = concatenate([x,y])\n",
        "    \n",
        "    out = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(ip, out)\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",metrics=['accuracy','AUC','Recall'])\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VLKMypislJ_"
      },
      "source": [
        "# Train on 90% data Dataset 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4DjSgHGvOne"
      },
      "source": [
        "np.random.seed(42)\n",
        "num_classes = 118\n",
        "X_train = load_X('/content/drive/Shareddrives/MMH/TIFS20/Dataset #1/train/Inertial Signals')\n",
        "X_test = load_X('/content/drive/Shareddrives/MMH/TIFS20/Dataset #1/test/Inertial Signals')\n",
        "train_label = load_y('/content/drive/Shareddrives/MMH/TIFS20/Dataset #1/train/y_train.txt')\n",
        "test_label = load_y('/content/drive/Shareddrives/MMH/TIFS20/Dataset #1/test/y_test.txt')\n",
        "shape = ((X_train.shape[1], X_train.shape[2]), train_label.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXMuAGghsrV9"
      },
      "source": [
        "if gpu:\n",
        "    model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "    history = model.fit(X_train,train_label,batch_size=32,epochs=200,verbose=1,callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)],validation_split=0.1)\n",
        "if tpu:\n",
        "    with strategy.scope():\n",
        "        model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "        history = model.fit(X_train,train_label,batch_size=8*32,epochs=200,verbose=1,callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)],validation_split=0.1)\n",
        "\n",
        "plot_performance(X_train, train_label, history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9h9HiAsuhNl"
      },
      "source": [
        "get_test_performance(model, X_test, test_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46JTDsKIwaov"
      },
      "source": [
        "# Train Full Manually Dataset 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uvg07AVXwn0j"
      },
      "source": [
        "#change \n",
        "epochs = 49\n",
        "if gpu:\n",
        "    model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "    history = model.fit(X_train,train_label,batch_size=32,epochs=epochs,verbose=1)\n",
        "if tpu:\n",
        "    with strategy.scope():\n",
        "        model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "        history = model.fit(X_train,train_label,batch_size=8*32,epochs=epochs,verbose=1)\n",
        "\n",
        "plot_performance(X_train, train_label, history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKwHIpwSzmU5"
      },
      "source": [
        "plot_performance(X_train, train_label, history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IOD0g9Zwdht"
      },
      "source": [
        "get_test_performance(model, X_test, test_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjGQsawPxWEb"
      },
      "source": [
        "# Train 90%  Dataset 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtYtKNSoxUJo"
      },
      "source": [
        "np.random.seed(42)\n",
        "X_train = load_X('/content/drive/Shareddrives/MMH/TIFS20/Dataset #2/train/Inertial Signals')\n",
        "X_test = load_X('/content/drive/Shareddrives/MMH/TIFS20/Dataset #2/test/Inertial Signals')\n",
        "train_label = load_y('/content/drive/Shareddrives/MMH/TIFS20/Dataset #2/train/y_train.txt')\n",
        "test_label = load_y('/content/drive/Shareddrives/MMH/TIFS20/Dataset #2/test/y_test.txt')\n",
        "shape = ((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "num_classes = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ_--h9yxUJo"
      },
      "source": [
        "if gpu:\n",
        "    model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "    history = model.fit(X_train,train_label,batch_size=32,epochs=200,verbose=1,callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)],validation_split=0.1)\n",
        "if tpu:\n",
        "    with strategy.scope():\n",
        "        model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "        history = model.fit(X_train,train_label,batch_size=8*32,epochs=200,verbose=1,callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)],validation_split=0.1)\n",
        "\n",
        "plot_performance(X_train, train_label, history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFae3hAAxUJp"
      },
      "source": [
        "get_test_performance(model, X_test, test_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuL2w_183XON"
      },
      "source": [
        "# y_prob = model.predict(X_test) \n",
        "# y_classes = y_prob.argmax(axis=-1)\n",
        "# features = model.predict(X_test)\n",
        "# from sklearn.manifold import TSNE\n",
        "# tsne = TSNE(n_components=2).fit_transform(features)\n",
        "# import pandas as pd\n",
        "# def scale_to_01_range(x):\n",
        "\n",
        "#     value_range = (np.max(x) - np.min(x))\n",
        "\n",
        "#     starts_from_zero = x - np.min(x)\n",
        "\n",
        "#     return starts_from_zero / value_range\n",
        "\n",
        "# tx = tsne[:, 0]\n",
        "# ty = tsne[:, 1]\n",
        "\n",
        "# tx = scale_to_01_range(tx)\n",
        "# ty = scale_to_01_range(ty)\n",
        "# tx = list(tx)\n",
        "# ty = list(ty)\n",
        "\n",
        "# data = {'tx':tx,\n",
        "#         'ty':ty}\n",
        "# df = pd.DataFrame(data)\n",
        "# df['y'] = y_classes\n",
        "# # fig = plt.figure()\n",
        "\n",
        "# # ax = fig.add_subplot(111)\n",
        "\n",
        "# plt.figure(figsize=(16,10))\n",
        "# sns.scatterplot(\n",
        "#     x=\"tx\", y=\"ty\",\n",
        "#     hue=\"y\",\n",
        "#     palette=sns.color_palette(\"flare\", as_cmap=True),\n",
        "#     data=df,\n",
        "#     legend=\"full\",\n",
        "#     alpha=0.3\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVk3TBGOyCnT"
      },
      "source": [
        "# Train Full Manually Dataset 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlreItAfyCnT"
      },
      "source": [
        "#change\n",
        "epochs = 15\n",
        "if gpu:\n",
        "    model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "    history = model.fit(X_train,train_label,batch_size=32,epochs=epochs,verbose=1)\n",
        "if tpu:\n",
        "    with strategy.scope():\n",
        "        model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "        history = model.fit(X_train,train_label,batch_size=8*32,epochs=epochs,verbose=1)\n",
        "\n",
        "plot_performance(X_train, train_label, history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m176YZ6yCnT"
      },
      "source": [
        "get_test_performance(model, X_test, test_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTR0FW2qzglG"
      },
      "source": [
        "# Train 90%  Dataset OU-ISIR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWT3WdxlzglG"
      },
      "source": [
        "num_classes = 745\n",
        "np.random.seed(42)\n",
        "X_train = load_X('/content/drive/Shareddrives/MMH/TIFS20/OU-ISIR_sensors_dataset/identification/data/train/data')\n",
        "X_test = load_X('/content/drive/Shareddrives/MMH/TIFS20/OU-ISIR_sensors_dataset/identification/data/test/data')\n",
        "train_label = load_y('/content/drive/Shareddrives/MMH/TIFS20/OU-ISIR_sensors_dataset/identification/data/train/train_y.txt')\n",
        "test_label = load_y('/content/drive/Shareddrives/MMH/TIFS20/OU-ISIR_sensors_dataset/identification/data/test/test_y.txt')\n",
        "print(f'{X_train.shape} {X_test.shape}')\n",
        "model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKQFT9GIzglH"
      },
      "source": [
        "if gpu:\n",
        "    model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "    history = model.fit(X_train,train_label,batch_size=32,epochs=200,verbose=1,callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)],validation_split=0.1)\n",
        "if tpu:\n",
        "    with strategy.scope():\n",
        "        model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "        history = model.fit(X_train,train_label,batch_size=8*32,epochs=200,verbose=1,callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)],validation_split=0.1)\n",
        "\n",
        "plot_performance(X_train, train_label, history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSFbB7aLzglH"
      },
      "source": [
        "get_test_performance(model, X_test, test_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKFZ_7IMzglH"
      },
      "source": [
        "# Train Full Manually Dataset OU-ISIR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gB6AKBRzglH"
      },
      "source": [
        "# change\n",
        "epochs = 54\n",
        "if gpu:\n",
        "    model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "    history = model.fit(X_train,train_label,batch_size=32,epochs=epochs,verbose=1)\n",
        "if tpu:\n",
        "    with strategy.scope():\n",
        "        model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "        history = model.fit(X_train,train_label,batch_size=8*32,epochs=epochs,verbose=1)\n",
        "\n",
        "plot_performance(X_train, train_label, history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2caGXHvzglH"
      },
      "source": [
        "get_test_performance(model, X_test, test_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VztWrRCA2pRd"
      },
      "source": [
        "# Train Dataset 1 test=val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1zEHVckto7S"
      },
      "source": [
        "if gpu:\n",
        "    model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "    history = model.fit(X_train,train_label,batch_size=32,epochs=200,verbose=1,callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)],validation_data=(X_test,test_label))\n",
        "if tpu:\n",
        "    with strategy.scope():\n",
        "        model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "        history = model.fit(X_train,train_label,batch_size=8*32,epochs=200,verbose=1,callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)],validation_data=(X_test,test_label))\n",
        "\n",
        "plot_performance(X_train, train_label, history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSIIcaHQuPMl"
      },
      "source": [
        "get_test_performance(model, X_test, test_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRezZ-Um0fYf"
      },
      "source": [
        "# Train dataset 2 test = val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGKgCzlru7oF"
      },
      "source": [
        "np.random.seed(42)\n",
        "X_train = load_X('/content/drive/Shareddrives/MMH/TIFS20/Dataset #2/train/Inertial Signals')\n",
        "X_test = load_X('/content/drive/Shareddrives/MMH/TIFS20/Dataset #2/test/Inertial Signals')\n",
        "train_label = load_y('/content/drive/Shareddrives/MMH/TIFS20/Dataset #2/train/y_train.txt')\n",
        "test_label = load_y('/content/drive/Shareddrives/MMH/TIFS20/Dataset #2/test/y_test.txt')\n",
        "shape = ((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "num_classes = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tRyFchR0a4v"
      },
      "source": [
        "if gpu:\n",
        "    model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "    history = model.fit(X_train,train_label,batch_size=32,epochs=200,verbose=1,callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)],validation_data=(X_test,test_label))\n",
        "if tpu:\n",
        "    with strategy.scope():\n",
        "        model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "        history = model.fit(X_train,train_label,batch_size=8*32,epochs=200,verbose=1,callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)],validation_data=(X_test,test_label))\n",
        "\n",
        "plot_performance(X_train, train_label, history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rssOilJ0caN"
      },
      "source": [
        "get_test_performance(model, X_test, test_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExiUFOeA0pua"
      },
      "source": [
        "#Train Test = val Dataset OU-ISIR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxJ37t7A0w2J"
      },
      "source": [
        "num_classes = 745\n",
        "np.random.seed(42)\n",
        "X_train = load_X('/content/drive/Shareddrives/MMH/TIFS20/OU-ISIR_sensors_dataset/identification/data/train/data')\n",
        "X_test = load_X('/content/drive/Shareddrives/MMH/TIFS20/OU-ISIR_sensors_dataset/identification/data/test/data')\n",
        "train_label = load_y('/content/drive/Shareddrives/MMH/TIFS20/OU-ISIR_sensors_dataset/identification/data/train/train_y.txt')\n",
        "test_label = load_y('/content/drive/Shareddrives/MMH/TIFS20/OU-ISIR_sensors_dataset/identification/data/test/test_y.txt')\n",
        "print(f'{X_train.shape} {X_test.shape}')\n",
        "model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6daQEds0zAk"
      },
      "source": [
        "if gpu:\n",
        "    model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "    history = model.fit(X_train,train_label,batch_size=32,epochs=200,verbose=1,callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)],validation_data=(X_test,test_label))\n",
        "if tpu:\n",
        "    with strategy.scope():\n",
        "        model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "        history = model.fit(X_train,train_label,batch_size=8*32,epochs=200,verbose=1,callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)],validation_data=(X_test,test_label))\n",
        "\n",
        "plot_performance(X_train, train_label, history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCCUCfyd01Fr"
      },
      "source": [
        "get_test_performance(model, X_test, test_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqmCcxhXqzr_"
      },
      "source": [
        "# Tune Test - > val "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4Ysihz6sSAq"
      },
      "source": [
        "np.random.seed(42)\n",
        "num_classes = 118\n",
        "X_train = load_X('/content/drive/Shareddrives/MMH/TIFS20/Dataset #1/train/Inertial Signals')\n",
        "X_test = load_X('/content/drive/Shareddrives/MMH/TIFS20/Dataset #1/test/Inertial Signals')\n",
        "train_label = load_y('/content/drive/Shareddrives/MMH/TIFS20/Dataset #1/train/y_train.txt')\n",
        "test_label = load_y('/content/drive/Shareddrives/MMH/TIFS20/Dataset #1/test/y_test.txt')\n",
        "shape = ((X_train.shape[1], X_train.shape[2]), train_label.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsIYkOjzsPP1"
      },
      "source": [
        "def post_se(hp):\n",
        "    ip = Input(shape=(6, 128))\n",
        "    x = Masking()(ip)\n",
        "    x = GRU(units=hp.Choice('gru_1', values = [8,16,32,64,128,256,512]))(x)\n",
        "    x = Dropout(hp.Choice(name='Dropout', values = [0.0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]))(x)\n",
        "    # x = GRU(units=hp.Choice('gru_2', values = [8,16,32,64,128,256,512]))(x)\n",
        "    # x = Dropout(hp.Choice(name='Dropout_2', values = [0.0,0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]))(x)\n",
        "    y = Permute((2, 1))(ip)\n",
        "    y = Conv1D(hp.Choice('conv_1_filter', values = [32,64,128,256,512]), hp.Choice(name='conv_1_filter_size', values = [3,5,7,8,9]), padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = squeeze_excite_block(y)\n",
        "    y = Conv1D(hp.Choice('conv_2_filter', values = [32,64,128,256,512]), hp.Choice(name='conv_2_filter_size',values = [3,5,7,8,9]), padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = squeeze_excite_block(y)\n",
        "    y = Conv1D(hp.Choice('conv_3_filter', values = [32,64,128,256,512]), hp.Choice(name='conv_3_filter_size',values = [3,5,7,8,9]), padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = GlobalAveragePooling1D()(y)\n",
        "    x = concatenate([x,y])\n",
        "    # batch_size = hp.Choice('batch_size', values=[32, 64, 128, 256, 512, 1024, 2048, 4096])\n",
        "    out = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(ip, out)\n",
        "    if gpu:\n",
        "        opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    if tpu:\n",
        "        opt = keras.optimizers.Adam(learning_rate=8*0.001)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "    # model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzBAQPTxpk_x"
      },
      "source": [
        "if gpu:\n",
        "    tuner = kt.tuners.BayesianOptimization(post_se,\n",
        "        objective='val_accuracy',\n",
        "        max_trials=30,\n",
        "        seed=42,\n",
        "        project_name='Model_gpu')\n",
        "    # Will stop training if the \"val_loss\" hasn't improved in 30 epochs.\n",
        "    tuner.search(X_train, train_label, epochs=200, validation_data=(X_test,test_label), shuffle=True, callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)])\n",
        "\n",
        "if tpu:\n",
        "    with strategy.scope():\n",
        "        tuner = kt.tuners.BayesianOptimization(post_se,\n",
        "            objective='val_accuracy',\n",
        "            max_trials=30,\n",
        "            seed=42,\n",
        "            project_name='Model_tpu_test')\n",
        "        # Will stop training if the \"val_loss\" hasn't improved in 30 epochs.\n",
        "        tuner.search(X_train, train_label, epochs=200, validation_data=(X_test,test_label), shuffle=True, callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwWBPV9HJUhg"
      },
      "source": [
        "# MODEL DEFINITION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5PaRlnv5WnW"
      },
      "source": [
        "def MLSTM_FCN(shape, num_classes):\n",
        "    x = Input(shape=(6, 128))\n",
        "    ip = x\n",
        "    x = Masking()(ip)\n",
        "    x = GRU(units=8)(x)\n",
        "    x = Dropout(0.8)(x)\n",
        "    y = Permute((2, 1))(ip)\n",
        "    y = Conv1D(32, 9, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = squeeze_excite_block(y)\n",
        "    y = Conv1D(256, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = squeeze_excite_block(y)\n",
        "    y = Conv1D(512, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = GlobalAveragePooling1D()(y)\n",
        "    x = concatenate([x,y])\n",
        "    \n",
        "    out = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(ip, out)\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",metrics=['accuracy','AUC','Recall'])\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqMIrG_L0dG1"
      },
      "source": [
        "# Train Dataset 1 test=val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrC9pmq90dG2"
      },
      "source": [
        "def MLSTM_FCN(shape, num_classes):\n",
        "    x = Input(shape=(6, 128))\n",
        "    ip = x\n",
        "    x = Masking()(ip)\n",
        "    x = GRU(units=8)(x)\n",
        "    x = Dropout(0.8)(x)\n",
        "    y = Permute((2, 1))(ip)\n",
        "    y = Conv1D(32, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = squeeze_excite_block(y)\n",
        "    y = Conv1D(512, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = squeeze_excite_block(y)\n",
        "    y = Conv1D(512, 9, padding='same', kernel_initializer='he_uniform')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = Activation('relu')(y)\n",
        "    y = GlobalAveragePooling1D()(y)\n",
        "    x = concatenate([x,y])\n",
        "    \n",
        "    out = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(ip, out)\n",
        "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",metrics=['accuracy','AUC','Recall'])\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKon6TKg0dG2"
      },
      "source": [
        "if gpu:\n",
        "    model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "    history = model.fit(X_train,train_label,batch_size=32,epochs=200,verbose=1,callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)],validation_data=(X_test,test_label))\n",
        "if tpu:\n",
        "    with strategy.scope():\n",
        "        model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "        history = model.fit(X_train,train_label,batch_size=8*32,epochs=200,verbose=1,callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)],validation_data=(X_test,test_label))\n",
        "\n",
        "plot_performance(X_train, train_label, history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8WIAbzl0dG2",
        "outputId": "1392fe20-2295-42a7-fd99-34635fca4077"
      },
      "source": [
        "get_test_performance(model, X_test, test_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "117/117 [==============================] - 2s 17ms/step - loss: 0.6572 - accuracy: 0.9425 - auc: 0.9813 - recall: 0.9412\n",
            "Test loss:0.6571820378303528\n",
            "Test accuracy:0.9425133466720581\n",
            "Test Recall: 0.9411764740943909\n",
            "Test AUC: 0.9812990427017212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL-gQ6yY0dG2"
      },
      "source": [
        "# Train dataset 2 test = val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeVdoRaK0dG2"
      },
      "source": [
        "np.random.seed(42)\n",
        "X_train = load_X('/content/drive/Shareddrives/MMH/TIFS20/Dataset #2/train/Inertial Signals')\n",
        "X_test = load_X('/content/drive/Shareddrives/MMH/TIFS20/Dataset #2/test/Inertial Signals')\n",
        "train_label = load_y('/content/drive/Shareddrives/MMH/TIFS20/Dataset #2/train/y_train.txt')\n",
        "test_label = load_y('/content/drive/Shareddrives/MMH/TIFS20/Dataset #2/test/y_test.txt')\n",
        "shape = ((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "num_classes = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBU1A99v0dG3"
      },
      "source": [
        "if gpu:\n",
        "    model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "    history = model.fit(X_train,train_label,batch_size=32,epochs=200,verbose=1,callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)],validation_data=(X_test,test_label))\n",
        "if tpu:\n",
        "    with strategy.scope():\n",
        "        model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "        history = model.fit(X_train,train_label,batch_size=8*32,epochs=200,verbose=1,callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)],validation_data=(X_test,test_label))\n",
        "\n",
        "plot_performance(X_train, train_label, history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuWbyign0dG3"
      },
      "source": [
        "get_test_performance(model, X_test, test_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3UeC-2t0dG3"
      },
      "source": [
        "#Train Test = val Dataset OU-ISIR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmhWjZAD0dG3"
      },
      "source": [
        "num_classes = 745\n",
        "np.random.seed(42)\n",
        "X_train = load_X('/content/drive/Shareddrives/MMH/TIFS20/OU-ISIR_sensors_dataset/identification/data/train/data')\n",
        "X_test = load_X('/content/drive/Shareddrives/MMH/TIFS20/OU-ISIR_sensors_dataset/identification/data/test/data')\n",
        "train_label = load_y('/content/drive/Shareddrives/MMH/TIFS20/OU-ISIR_sensors_dataset/identification/data/train/train_y.txt')\n",
        "test_label = load_y('/content/drive/Shareddrives/MMH/TIFS20/OU-ISIR_sensors_dataset/identification/data/test/test_y.txt')\n",
        "print(f'{X_train.shape} {X_test.shape}')\n",
        "model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhLx6Wpz0dG3"
      },
      "source": [
        "if gpu:\n",
        "    model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "    history = model.fit(X_train,train_label,batch_size=32,epochs=200,verbose=1,callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)],validation_data=(X_test,test_label))\n",
        "if tpu:\n",
        "    with strategy.scope():\n",
        "        model = MLSTM_FCN((X_train.shape[1], X_train.shape[2]), train_label.shape[1])\n",
        "        history = model.fit(X_train,train_label,batch_size=8*32,epochs=200,verbose=1,callbacks=[tensorflow.keras.callbacks.EarlyStopping('val_loss', patience=30)],validation_data=(X_test,test_label))\n",
        "\n",
        "plot_performance(X_train, train_label, history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab6K_-wl0dG3"
      },
      "source": [
        "get_test_performance(model, X_test, test_label)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}